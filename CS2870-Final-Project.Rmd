---
title: "CS2870-Final-Project"
output:
  html_document:
    df_print: paged
date: "2023-11-14"
authors: Yoni Masha, Charlie Corriero
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
pacman::p_load(tidyverse, dplyr, usmap, maps, ggthemes, sf, lubridate, scales, class, caret, rpart, rpart.plot)
crime_data_sample <- read_csv("Crime_Data_from_2020_to_Present.csv")

us_states <- map_data(map = "state")
us_counties <- map_data(map = "county")

theme_set(theme_map())
```


# Intro

The source for our data is kaggle.com and the data set was created on October 12, 2023. This data is not a sample as it is all the crime data from the year 2020 to the present (2023), and because of this, it does not have any sampling bias. The data from this set was collected from data.gov and was created in November of 2020 and has been regularly updated since, and is maintained by LAPD OpenData. This was an observational study looking at all the crimes that occurred from 2020-2023. This data is of interest to us because we think that analyzing crime data could help people to better understand when/where/why crimes occur and what can be predicted based on the data. As for cleaning the data, we first cut the data set in half because it was too large and making graphs, manipulating the data, etc was taking longer than we wanted. Next we used dplyr::select() to keep the columns that we thought were relevant to the graphs we were going to make and the machine learning we planned to implement. After that we used rename() to rename the columns to something more readable and intuitive and used mutate() to remove unnecessary white space from our 'location' column. Lastly, we used filter to keep the rows where the age was in the range we wanted (0 to 90), the latitude and longitude weren't equal to zero, and the rows did not contain NA or no value.


```{r cleaning}
RNGversion("4.1.0"); set.seed(2870)

crime_data_sample |>
  slice_sample(prop = 0.5)

# Selecting the columns we want to work with
crime_data_sample |>
  dplyr::select(`Date Rptd`, `DATE OCC`, `TIME OCC`, AREA, `AREA NAME`, `Crm Cd Desc`,`Crm Cd` ,`Vict Age`, `Vict Sex`, `Vict Descent`,
                `Premis Desc`, `Weapon Desc`, `Status Desc`, LOCATION, LAT, LON) |>
  
    # Renaming the columns to be more readable
  rename(
    "date_reported" = `Date Rptd`, 
    "date_occurred" = `DATE OCC`,
    "time_occurred" = `TIME OCC`,
    "area" = AREA,
    "area_name" = `AREA NAME`,
    "crime_description" = `Crm Cd Desc`,
    "crime_code" = `Crm Cd`,
    "victim_age" = `Vict Age`,
    "victim_sex" = `Vict Sex`,
    "victim_descent" = `Vict Descent`,
    "premise_desc" = `Premis Desc`,
    "weapon_desc" = `Weapon Desc`,
    "status" = `Status Desc`,
    "location" = LOCATION,
    "lat" = LAT,
    "long" = LON
  ) |>
  
    # Removing unnecessary whitesapce from the 'location' column
  mutate(location = str_squish(location)) |>
  
    # Removing NA values, keeping rows within our desired age range (0-90), and removing rows where the latitude and longitude is 0
  filter(
    victim_age > 0 & victim_age <= 90,
    !is.na(victim_sex),
    !is.na(victim_descent),
    !is.na(date_reported),
    !is.na(date_occurred),
    !is.na(time_occurred),
    !is.na(area),
    !is.na(area_name),
    !is.na(crime_description),
    !is.na(crime_code),
    !is.na(premise_desc),
    !is.na(victim_age),
    !is.na(status),
    !is.na(location),
    lat != 0 & long != 0,
    !is.na(lat),
    !is.na(long)
  ) |>
  
    # Taking 50% of the data so the code chunks run faster
  slice_sample(prop = .5) ->
  
  crime_data

```


```{r victim_sex/crime analysis}

# Creating the graph
ggplot(
  data = crime_data,
  mapping = aes(
    x = victim_age
  ),
) +
    
  # Adding the histogram
  geom_histogram(
    color = "black",
    fill = "firebrick",
    bins = 30
  ) +
  
  # Changing plot labels
  labs(
    x = "Age of Victim",
    y = "Number of Crimes",
    title = "Number of Crimes Committed on People of Age X"
  ) +
  
  # Changing the look of the graph
  theme(
    plot.background = element_rect(fill = "gray17"),
    panel.background = element_rect(fill = "gray17"),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text = element_text(color = "gray"),
    axis.line.x = element_line(color = "gray"),
    axis.line.y = element_line(color = "gray"),
    axis.title.x = element_text(color = "gray"),
    axis.title.y = element_text(color = "gray"),
    plot.title = element_text(color = "gray", hjust = .5)
  ) +
  
  # Fixing y scales
  scale_y_continuous(
    expand = c(0,0,0.25,0),
    breaks = c(0,5000,10000,15000,20000,25000,30000)
  ) +
  
  # Fixing x scales
  scale_x_continuous(
    expand = c(0.025,0.05,0.05,0),
    breaks = c(0,10,20,30,40,50,60,70,80,90)
  )

```

# Interpretation

It can be seen that the age range with the highest number of crimes committed against it is the age range of 25-43, and after 43 is steadily declines. Up until the age of adulthood (18) you are also less likely to have a crime committed against you which makes sense, since most crimes do not happen to children. The graph also resembles a Chi^2 distribution curve, Which suggests that the data isn't uniform and follows a specific pattern. This makes sense because 18-30 year olds are more likely to participate in criminal activity.



```{r time of day for crime}
# Making a new data-frame for the times and converting them from military to regular
crime_data |>
  dplyr::select(time_occurred, ) |>
  
  group_by(time_occurred) |>
  
  mutate(time_occurred = floor(as.numeric(time_occurred) / 100) * 100,
         occurrences = n()) |>
  
  distinct(time_occurred,.keep_all = TRUE) |>
  
  ungroup() ->
  crime_times



# Creating 2 vectors, one for the labels for the graph and one for the breaks on the graph
time_labels <- c("12pm", "1am", "2am", "3am", "4am", "5am", "6am", "7am", "8am", "9am", "10am", "11am", "12am", "1pm", "2pm", "3pm", "4pm", "5pm", "6pm", "7pm", "8pm", "9pm", "10pm", "11pm")
time_breaks <- seq(from = 0, to = 2300, by = 100)

# Creating the graoh
ggplot(data = crime_times,
       mapping = aes(
         x = time_occurred,
         y = occurrences,
         fill = occurrences
       )) +
  
  # Adding the columns
  geom_col() +
  
  # Setting the base theme
  theme_bw() +
  
  # Using the previously made vectors to set the breaks and labels
  scale_x_continuous(breaks = time_breaks,
                     labels = time_labels,
                     minor_breaks = F,
                     expand = c(0.01,0.01)) +
  
  scale_y_continuous(expand = c(0,0,0.03,0)) +
  
  # Setting the title, x and y axis labels, and legend title
  labs(x = "Time",
       y = "Number of crimes that occured",
       title = "Number of Crimes that Occurred During Each Hour",
       fill = 'Occurences') + 
  
  theme(
        # Text elements
        axis.text.x = element_text(angle = 45, hjust = 1),
        legend.text = element_text(color = "gray"),
        legend.title = element_text(color = "gray"),
        plot.title = element_text(hjust=0.5, size = 15, color = "gray"),
        axis.text = element_text(color = "gray"),
        
        # Rect elements
        legend.background = element_rect(fill = "gray17"),
        panel.background = element_rect(fill = "gray17"),
        plot.background = element_rect(fill = "gray17"),
        
        # Blank elements
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        
        # Line elements
        axis.line.x = element_line(color = "gray"),
        axis.line.y = element_line(color = "gray"),
        axis.title.x = element_text(color = "gray"),
        axis.title.y = element_text(color = "gray"),
        
        # Other elements
        legend.key.height = unit(1, "cm")
        ) +
  

  # Changing the breaks, labels, and colors for the graph  
  scale_fill_gradient(low = "green", high = "red",
                      limits = c(0, 7500), 
                      breaks = c(0, 1000, 2000, 3000, 4000, 5000, 6000, 7000),
                      labels = c(0, 1000, 2000, 3000, 4000, 5000, 6000, 7000))

```

# Interpretation
As seen in the graph there is a spike in crime rates after 5pm, this makes sense because as it gets darker out it is harder for the criminal to be seen committing the crime so they are more likely to try to commit it when its dark. There are some times in the graph that show little to no crime but I don't think that means that no crimes are committed. I would assume that the crimes committed during those times aren't well documented and during our data cleaning, they were removed because of that. This could be due to less police on duty during that time and more criminals getting away with their crimes. It seems like the safest times are from the hours of 2am to 8am, with a spike of crime from 9am to 3pm, and then it is at its highest from 7pm to 12am. 

```{r descent bar plot}

# Making new data set to have a new column with the number of occurrences of crime for each descent
crime_data_descent <-
  
  crime_data |>
  
  group_by(victim_descent) |>
  
  mutate(
    occurrences = n()
  ) |>
  
  # Keeping one of each
  distinct(victim_descent,.keep_all = TRUE) |>
  
  select(victim_descent, occurrences)
  

ggplot(
  data = crime_data_descent,
  mapping = aes(
    y = reorder(x = victim_descent, X = occurrences),
    x = occurrences,
    fill = occurrences,
    label = occurrences
  )
) +
  
  geom_col() +
  
  # Adding text at the end for the very small values
  geom_text(
    aes(x = occurrences + 5000, label = occurrences),
    color = "white", 
    size = 3.25  
  ) +
  
  theme_bw() +
  
  theme(
    plot.title = element_text(color = "gray" ,hjust = 0.5),
    plot.background = element_rect(fill = "gray17"),
    panel.background = element_rect(fill = "gray17"),
    axis.text = element_text(color = "gray"),
    axis.line.x = element_line(color = "gray"),
    axis.line.y = element_line(color = "gray"),
    axis.title.x = element_text(color = "gray"),
    axis.title.y = element_text(color = "gray"),
    axis.ticks.y = element_line(color = "gray"),
    axis.ticks.x = element_line(color = "gray"),
    legend.position = "none",
    panel.grid.major.x = element_line(color = "gray30"),
    panel.grid.major.y = element_line(color = "gray30"),
    panel.grid.minor.x =element_line(color = "gray30")
  ) +
  
  labs(
    x = "Crimes Commited",
    y = "Victim Descent",
    title = "Number of Crimes Against Victim Based on Descent in LA"
  ) +

  # Changing formatting to make it more readable
  scale_y_discrete(
    labels = c(
      "H" = "Hispanic",
      "B" = "Black",
      "O" = "Other",
      "A" = "Other Asian",
      "W" = "White",
      "X" = "Unknown",
      "K" = "Korean",
      "F" = "Filipino",
      "C" = "Chinese",
      "J" = "Japanese",
      "V" = "Viatnamese",
      "I" = "American Indian/\nAlaskan Native",
      "Z" = "Asian Indian",
      "P" = "Pacific Islander",
      "U" = "Hawaiian",
      "G" = "Guamanian",
      "D" = "Cambodian",
      "S" = "Samoan",
      "L" = "Laotian"
    ),
    expand = c(0,0,0,0)
  ) +
  
  scale_fill_gradient(
    low = "gold",
    high = "firebrick1"  
  ) +
  
  scale_x_continuous(
    expand = c(0.0075,0,0.05,0),
    breaks = c(0,25000,50000,75000,100000,125000,150000)
  )

#Vict Descent - Descent Code: A - Other Asian B - Black C - Chinese D - Cambodian F - Filipino G - Guamanian H - #Hispanic/Latin/Mexican I - American Indian/Alaskan Native J - Japanese K - Korean L - Laotian O - Other P - Pacific #Islander S - Samoan U - Hawaiian V - Vietnamese W - White X - Unknown Z - Asian Indian



```

## Interpretation
In this graph, we observe the number of crimes committed against people of each of the descents listed. People of Hispanic descent have a significantly higher chance of having a crime committed against them, having 50000 more crimes than people of White descent which is in second place. It is also worth noting that Hispanic people make up around 40-50% of Los Angeles' population. It is still surprising however due to the fact that people of White descent still have a significantly lower chance of having a crime committed against them. After the "Other" category, we observe a huge drop off, most likely due to there not being a large population of people of those descents residing in Los Angeles county. 


``` {r Crime by Sex}

# Making new data set to add the number of months since 2020 to each crime
crime_data_date <- 
  crime_data |>
  
  # Date formatting
  mutate(date = as.Date(date_occurred, format = "%m/%d/%Y %I:%M:%S %p"),
         months_since_2020 = (year(date) - 2020) * 12 + month(date)) |>
  
  # Keeping it less than 45 because there are not enough observations past 45
  filter((victim_sex == "M" | victim_sex == "F") & months_since_2020 <= 45)


# Created a new data set with the months since 2020, the sex of the victim, and the crime count to make a line
crime_summarized <- crime_data_date |>
  
  group_by(months_since_2020, victim_sex) |>
  
  summarise(crime_count = n())

ggplot(
  data = crime_summarized,
  mapping = aes(
    x = months_since_2020,
    y = crime_count,
    group = victim_sex,
    color = victim_sex
  )
) +
  
  geom_line() +
  
  
  theme_classic() +
  
  labs(
    x = "Months since January 2020",
    y = "Crime Count",
    color = "Victim Sex",
    title = "Number of Crimes Commited Against Each Sex Since 2020"
  ) +
  
  theme(
    plot.title = element_text(color = "gray" ,hjust = 0.5),
    legend.position = c(0.75, 0.25),
    plot.background = element_rect(fill = "gray17"),
    panel.background = element_rect(fill = "gray17"),
    axis.text = element_text(color = "gray"),
    axis.line.x = element_line(color = "gray"),
    axis.line.y = element_line(color = "gray"),
    axis.title.x = element_text(color = "gray"),
    axis.title.y = element_text(color = "gray"),
    legend.background = element_rect(fill = "gray17"),
    legend.title = element_text(color = "gray"),
    legend.text = element_text(color = "gray")
  ) +
  
  scale_x_continuous(
    expand = c(0,0,0,0),
    breaks = c(seq(0,50,5))
  ) +
  
  scale_y_continuous(
    expand = c(0.05,0,0.05,0),
    breaks = c(seq(2500,4000,250))
  ) +
  
  scale_color_manual(
    values = c("M" = "steelblue1", "F" = "hotpink"),
    labels = c("F" = "Female", "M" = "Male")
  )


```



In this graph, we observe the number of crimes committed on male and female persons since 2020. The part that strikes me about this graph is during the time of the pandemic both male and female crimes drop significantly. We can also observe that around a year and a half later (15 months on this graph) the crimes start to pick up again which is when mandates started to become more lenient and people were leaving there houses more and more. 

Although it makes sense in this graph that males are on the receiving end of most crimes, it strikes me that females around 2 years after 2020 start to experience more crimes than the males, even spiking at around 34 months. I don't think there is any particular causation of this, but it is interesting nonetheless. Finally, there is a significant drop off at 45 months, but that is most likely because crimes were not reported as much because of the new year. 

``` {r dumbbell plot age, gender, and crime}
crime_data |>
  
  group_by(victim_sex) |> 
  
  mutate(
    condensed_crime = case_when(
      grepl("battery&sexual|sex|lewd|indecent|peeping|oral", tolower(crime_description)) ~ "Sexual Assault",
      grepl("assault|battery", tolower(crime_description)) ~ "Assault",
      grepl("robbery|theft|extortion|stolen|stole|steal|pickpocket", tolower(crime_description)) ~ "Robbery",
      grepl("rape", tolower(crime_description)) ~ "Rape",
      grepl("vandalism", tolower(crime_description)) ~ "Vandalism",
      grepl("trespassing", tolower(crime_description)) ~ "Tresspassing",
      grepl("arson", tolower(crime_description)) ~ "Arson",
      grepl("neglect|abuse", tolower(crime_description)) ~ "Abuse/Neglect",
      grepl("weapon|firearm|bomb", tolower(crime_description)) ~ "Weapons Related",
      grepl("kidnap|child steal", tolower(crime_description)) ~ "Kidnapping"
    )
  ) |>
  
  group_by(condensed_crime) |>
  
  summarise(
    avg_age_male = mean(ifelse(victim_sex == "M" & !is.na(victim_age), victim_age, NA), na.rm = TRUE),
    avg_age_female = mean(ifelse(victim_sex == "F" & !is.na(victim_age), victim_age, NA), na.rm = TRUE)
  ) |>
  
  dplyr::select(condensed_crime, avg_age_male, avg_age_female) |>
  
  filter(!is.na(condensed_crime)) |>
  
  distinct(condensed_crime, .keep_all = T) ->
  
  crime_data_crimes_clean


ggplot(
  data = crime_data_crimes_clean,
  mapping = aes(
    y = fct_reorder(condensed_crime, avg_age_male, .fun = min)
  )
) +
  
  geom_segment(
    mapping = aes(
      x = avg_age_male, xend = avg_age_female, yend = condensed_crime
    ),
    color = "gray"
  ) +
  
  geom_point(
    mapping = aes(x = avg_age_female),
    color = "hotpink"
  ) +
  
  geom_point(
    mapping = aes(x = avg_age_male),
    color = "steelblue1"
  ) +
  
  theme_classic() +
  
  labs(
    title = "Female Avg Age Vs Male Avg Age For Each Crime",
    y = "Type of Crime",
    x = "Age"
  ) +
  
  theme(
    plot.title = element_text(color = "gray" ,hjust = 0.5),
    plot.background = element_rect(fill = "gray17"),
    panel.background = element_rect(fill = "gray17"),
    axis.text = element_text(color = "gray"),
    axis.line.x = element_line(color = "gray"),
    axis.line.y = element_line(color = "gray"),
    axis.title.x = element_text(color = "gray"),
    axis.title.y = element_text(color = "gray"),
    axis.ticks = element_blank()
  ) +
  
  scale_x_continuous(
    breaks = seq(0,50,5)
  )
```


```{r Normalizing/Standardizng and finding which is better}
# Create normalization function
normalize <- function(x){
  return((x - min(x)) / (max(x) - min(x) ))
}

# Create standardization function
standardize <- function(x) {
  return((x - mean(x)) / sd(x))
}

```

```{r knn sex by crime type and time}
RNGversion("4.1.0"); set.seed(2870)

crime_data |>

  mutate(
    condensed_crime = case_when(
      grepl("battery&sexual|sex|lewd|indecent|peeping|oral", tolower(crime_description)) ~ "Sexual Assault",
      grepl("assault|battery", tolower(crime_description)) ~ "Assault",
      grepl("robbery|theft|extortion|stolen|stole|steal|pickpocket", tolower(crime_description)) ~ "Robbery",
      grepl("rape", tolower(crime_description)) ~ "Rape",
      grepl("vandalism", tolower(crime_description)) ~ "Vandalism",
      grepl("trespassing", tolower(crime_description)) ~ "Tresspassing",
      grepl("arson", tolower(crime_description)) ~ "Arson",
      grepl("neglect|abuse", tolower(crime_description)) ~ "Abuse/Neglect",
      grepl("weapon|firearm|bomb", tolower(crime_description)) ~ "Weapons Related",
      grepl("kidnap|child steal", tolower(crime_description)) ~ "Kidnapping"
    )
  ) |>
  filter(!is.na(condensed_crime),
         victim_sex != "X") |>
  dplyr::select(victim_age, crime_code, victim_sex) |>
  slice_sample(n = 500)->
  
  crime_data_crimes_clean_knn

ml_crimes <- 
  crime_data_crimes_clean_knn

# Normalized data
crime_data_norm <- 
  ml_crimes |>
  mutate(across(.cols = where(is.numeric),
                .fns = normalize))

# Standardized data
crime_data_stan <- 
  ml_crimes |>
  mutate(across(.cols = where(is.numeric),
                .fns = standardize))


# Setting up results data frame
knn_results <- 
  tibble(
    k = 1:500,
    norm_acc = rep(-1, length(k)),
    stan_acc = rep(-1, length(k))
  )

# Putting the results of stan and norm data into a dataframe
for(i in 1:nrow(knn_results)) {
  
  loop_norm <- 
    knn.cv(
      train = crime_data_norm |> dplyr::select(-victim_sex),
      cl = crime_data_norm$victim_sex,
      k = knn_results$k[i]
    )
  
  knn_results[i, "norm_acc"] = mean(loop_norm == ml_crimes$victim_sex)
  
  
  loop_stan <- 
    knn.cv(
      train = crime_data_stan |> dplyr::select(-victim_sex),
      cl = crime_data_stan$victim_sex,
      k = knn_results$k[i]
    )
  
  knn_results[i, "stan_acc"] = mean(loop_stan == ml_crimes$victim_sex)
  
}


# Finding the max 
norm_max <- max(knn_results$norm_acc)
stan_max <- max(knn_results$stan_acc)

norm_max_x <- mean(knn_results$k[knn_results$norm_acc == norm_max])
stan_max_x <- knn_results$k[knn_results$stan_acc == stan_max]

c("Maximum norm accuracy" = norm_max,
  "K value associated with the maximum of norm" = norm_max_x,
  "Maximum stan accuracy" = stan_max,
  "K value associated with the maximum of stan" = stan_max_x)


```

```{r knn 2}
RNGversion("4.1.0"); set.seed(2870)
# Making a new data frame with only the variables needed
crime_data |>
  dplyr::select(time_occurred, victim_age, victim_sex) |>
  mutate(time_occurred = as.numeric(time_occurred)) |>
  filter(victim_sex != "X") |>
  slice_sample(n = 500)->
  ml_crime

# Using the same data for the testing data frame
crime_for_knn <- 
  ml_crime


knn_crime <- 
  knn(
    train = crime_data_stan |> select(where(is.numeric)),
    test = crime_data_stan |> select(where(is.numeric)),
    cl = crime_for_knn$victim_sex,
    k = 142
  )

table(actual = crime_for_knn$victim_sex,
      predicted = knn_crime)

```



```{r classification tree}
RNGversion("4.1.0"); set.seed(2870)
tree_full <- 
  rpart(
    formula = victim_sex ~ time_occurred + victim_age,
    data = ml_crime,
    method = "class",
    parms = list(split = "information"),
    minsplit = 2,
    minbucket = 1,
    cp = -1
  )

rpart.plot(
  x = tree_full
)
```

```{r pruning}

tree_full$cptable |>
  data.frame() |>
  slice_min(xerror, n = 1) |>
  mutate(xcutoff = xerror + xstd) |>
  pull(xcutoff) |>
  head(1) ->
  xcutoff

tree_full$cptable |>
  data.frame() |>
  filter(xerror < xcutoff) |>
  slice(1) |>
  pull(CP) ->
  cp_cutoff

```
```{r pruned tree}
prune(tree = tree_full,
      cp = cp_cutoff) ->
  tree_pruned


# Plot the tree
rpart.plot(
  x = tree_pruned
)

```


# Interpretation
In this graph, we observe the number of crimes committed on male and female persons since 2020. The part that strikes me about this graph is during the time of the pandemic both male and female crimes drop significantly. We can also observe that around a year and a half later (15 months on this graph) the crimes start to pick up again which is when mandates started to become more lenient and people were leaving there houses more and more. 

Although it makes sense in this graph that males are on the receiving end of most crimes, it strikes me that females around 2 years after 2020 start to experience more crimes than the males, even spiking at around 34 months. I don't think there is any particular causation of this, but it is interesting nonetheless. Finally, there is a significant drop off at 45 months, but that is most likely because crimes were not reported as much because of the new year. 




## Conclusion

During our analysis, we found that middle aged citizens are most likely to have a crime committed against them, the ages with the highest amount of crimes committed against them were ages 25-43. We also found that the most dangerous times of the day in terms of crime are from the hours of 7pm to midnight with the highest number of crimes being committed during these hours, the safest times are 2am to 8am. According to the data, Hispanic people are most likely to have a crime committed against them, Being follow by White and Black people respectively. During Covid the crime rates overall dropped significantly. They went back up over the years and eventually the crime rates against females rose above those of males.


## Limitations and Reccomendation

The first limitation that we found was that not all of the crimes we well documented, with many missing key information about the committed crime. The crimes with little documentation were removed from our data set during cleaning. We also found that at certain times crimes seemed to not be documented well either, as seen in the crimes by time graph. Future researches could include crimes from areas that are not only in Los Angeles. Researches could also look deeper at each of the graphs that we made and find the underlying 'why' to the trends that are seen in them.
